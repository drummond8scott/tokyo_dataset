{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzgsB18x24Z0JVyC37jNHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drummond8scott/tokyo_dataset/blob/main/tokyo_dataset_de.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages for loading, transforming and exporting tokyo data\n",
        "import openpyxl\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (col, upper, trim, regexp_replace, when, count,\n",
        "                                 initcap, concat_ws, split, to_timestamp, coalesce, isnan, when, length, trim,\n",
        "                                 sum as spark_sum, countDistinct, desc, expr, round)\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "ZvI4DMJ3v1eJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WtLlijKTSNt4",
        "outputId": "791d95f4-4cca-4d12-b20a-26eb97a17779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Sizes:\n",
            "Athletes: 11085 records\n",
            "Coaches: 394 records\n",
            "Medals: 93 records\n",
            "Teams: 743 records\n",
            "\n",
            "First few rows of each dataset:\n",
            "\n",
            "Athletes dataset:\n",
            "                Name     NOC           Discipline\n",
            "0    AALERUD Katrine  Norway         Cycling Road\n",
            "1        ABAD Nestor   Spain  Artistic Gymnastics\n",
            "2  ABAGNALE Giovanni   Italy               Rowing\n",
            "\n",
            "Coaches dataset:\n",
            "              Name    NOC  Discipline Event\n",
            "0  ABDELMAGID Wael  Egypt    Football   NaN\n",
            "1        ABE Junya  Japan  Volleyball   NaN\n",
            "2    ABE Katsuhiko  Japan  Basketball   NaN\n",
            "\n",
            "Medals dataset:\n",
            "   Rank                    Team/NOC  Gold  Silver  Bronze  Total  \\\n",
            "0     1    United States of America    39      41      33    113   \n",
            "1     2  People's Republic of China    38      32      18     88   \n",
            "2     3                       Japan    27      14      17     58   \n",
            "\n",
            "   Rank by Total  \n",
            "0              1  \n",
            "1              2  \n",
            "2              5  \n",
            "\n",
            "Teams dataset:\n",
            "      Name      Discipline                         NOC  Event\n",
            "0  Belgium  3x3 Basketball                     Belgium    Men\n",
            "1    China  3x3 Basketball  People's Republic of China    Men\n",
            "2    China  3x3 Basketball  People's Republic of China  Women\n"
          ]
        }
      ],
      "source": [
        "# Base URL for raw GitHub content\n",
        "base_url = \"https://raw.githubusercontent.com/drummond8scott/tokyo_dataset/main/\"\n",
        "\n",
        "# Load datasets\n",
        "athletes_df = pd.read_excel(base_url + \"Athletes.xlsx\")\n",
        "coaches_df = pd.read_excel(base_url + \"Coaches.xlsx\")\n",
        "medals_df = pd.read_excel(base_url + \"Medals.xlsx\")\n",
        "teams_df = pd.read_excel(base_url + \"Teams.xlsx\")\n",
        "\n",
        "# Print counts for loaded datasets\n",
        "print(\"Dataset Sizes:\")\n",
        "print(f\"Athletes: {len(athletes_df)} records\")\n",
        "print(f\"Coaches: {len(coaches_df)} records\")\n",
        "print(f\"Medals: {len(medals_df)} records\")\n",
        "print(f\"Teams: {len(teams_df)} records\")\n",
        "\n",
        "# Print first 3 rows of each dataset\n",
        "print(\"\\nFirst few rows of each dataset:\")\n",
        "for name, df in [(\"Athletes\", athletes_df), (\"Coaches\", coaches_df),\n",
        "                 (\"Medals\", medals_df), (\"Teams\", teams_df)]:\n",
        "    print(f\"\\n{name} dataset:\")\n",
        "    print(df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pandas dataframes to PySpark dataframes\n",
        "athletes_df = spark.createDataFrame(athletes_df)\n",
        "coaches_df = spark.createDataFrame(coaches_df)\n",
        "medals_df = spark.createDataFrame(medals_df)\n",
        "teams_df = spark.createDataFrame(teams_df)"
      ],
      "metadata": {
        "id": "-MZc9xZHz7M_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Athletes DataFrame Analysis\n",
        "print(\"=== ATHLETES DATASET ANALYSIS ===\")\n",
        "total_athletes = athletes_df.count()\n",
        "print(f\"Total athletes: {total_athletes}\")\n",
        "\n",
        "# Check missing values in athletes\n",
        "for column in athletes_df.columns:\n",
        "    null_count = athletes_df.filter(col(column).isNull()).count()\n",
        "    if null_count > 0:\n",
        "        print(f\"Missing values in {column}: {null_count} ({(null_count/total_athletes*100):.2f}%)\")\n",
        "\n",
        "# Check for duplicate athletes\n",
        "duplicate_athletes = athletes_df.groupBy(athletes_df.columns).count().filter(\"count > 1\")\n",
        "if duplicate_athletes.count() > 0:\n",
        "    print(f\"\\nFound {duplicate_athletes.count()} duplicate athlete entries\")\n",
        "\n",
        "\n",
        "# Check NOC distribution\n",
        "noc_counts = athletes_df.groupBy(\"NOC\").count().orderBy(\"count\", ascending=False)\n",
        "print(\"\\nTop 5 NOCs by athlete count:\")\n",
        "noc_counts.show(5)\n",
        "\n",
        "print(\"\\n=== MEDALS DATASET ANALYSIS ===\")\n",
        "total_medal_records = medals_df.count()\n",
        "print(f\"Total medal records: {total_medal_records}\")\n",
        "\n",
        "# Check missing values in medals\n",
        "for column in medals_df.columns:\n",
        "    null_count = medals_df.filter(col(column).isNull()).count()\n",
        "    if null_count > 0:\n",
        "        print(f\"Missing values in {column}: {null_count} ({(null_count/total_medal_records*100):.2f}%)\")\n",
        "\n",
        "# Check medal counts by type - Modified to handle separate medal columns\n",
        "medal_distribution = medals_df.select(\n",
        "    sum(col(\"Gold\")).alias(\"Gold\"),\n",
        "    sum(col(\"Silver\")).alias(\"Silver\"),\n",
        "    sum(col(\"Bronze\")).alias(\"Bronze\")\n",
        ").withColumn(\"Total\", col(\"Gold\") + col(\"Silver\") + col(\"Bronze\"))\n",
        "\n",
        "print(\"\\nMedal distribution:\")\n",
        "medal_distribution.show()\n",
        "\n",
        "# Cross-reference check between athletes and medals\n",
        "athlete_countries = athletes_df.select(\"NOC\").distinct().count()\n",
        "medal_countries = medals_df.select(\"Team/NOC\").distinct().count()\n",
        "print(f\"\\nUnique countries in athletes: {athlete_countries}\")\n",
        "print(f\"Unique countries in medals: {medal_countries}\")\n",
        "\n",
        "print(\"\\n=== DATA CONSISTENCY CHECKS ===\")\n",
        "# Check for any NOCs in medals that don't appear in athletes\n",
        "medals_nocs = set(medals_df.select(\"Team/NOC\").distinct().collect())\n",
        "athletes_nocs = set(athletes_df.select(\"NOC\").distinct().collect())\n",
        "mismatched_nocs = medals_nocs - athletes_nocs\n",
        "if mismatched_nocs:\n",
        "    print(f\"NOCs in medals but not in athletes: {mismatched_nocs}\")\n",
        "\n",
        "# Check for unusual values in key fields\n",
        "print(\"\\nUnique disciplines:\")\n",
        "athletes_df.select(\"Discipline\").distinct().show(truncate=False)\n",
        "\n",
        "print(\"\\nSample of unusual names (if any):\")\n",
        "athletes_df.filter(~col(\"Name\").rlike(\"^[A-Za-z\\\\s\\\\-\\\\']+$\")).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_GgLJgc46xg",
        "outputId": "39ac66a0-939a-4bf3-c3fd-d7df1cee9224"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ATHLETES DATASET ANALYSIS ===\n",
            "Total athletes: 11085\n",
            "\n",
            "Found 1 duplicate athlete entries\n",
            "\n",
            "Top 5 NOCs by athlete count:\n",
            "+--------------------+-----+\n",
            "|                 NOC|count|\n",
            "+--------------------+-----+\n",
            "|United States of ...|  615|\n",
            "|               Japan|  586|\n",
            "|           Australia|  470|\n",
            "|People's Republic...|  401|\n",
            "|             Germany|  400|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "=== MEDALS DATASET ANALYSIS ===\n",
            "Total medal records: 93\n",
            "\n",
            "Medal distribution:\n",
            "+----+------+------+-----+\n",
            "|Gold|Silver|Bronze|Total|\n",
            "+----+------+------+-----+\n",
            "| 340|   338|   402| 1080|\n",
            "+----+------+------+-----+\n",
            "\n",
            "\n",
            "Unique countries in athletes: 206\n",
            "Unique countries in medals: 93\n",
            "\n",
            "=== DATA CONSISTENCY CHECKS ===\n",
            "\n",
            "Unique disciplines:\n",
            "+---------------------+\n",
            "|Discipline           |\n",
            "+---------------------+\n",
            "|Tennis               |\n",
            "|Boxing               |\n",
            "|Marathon Swimming    |\n",
            "|Golf                 |\n",
            "|Rowing               |\n",
            "|Baseball/Softball    |\n",
            "|Judo                 |\n",
            "|Sailing              |\n",
            "|Swimming             |\n",
            "|Cycling BMX Freestyle|\n",
            "|Basketball           |\n",
            "|Handball             |\n",
            "|Rhythmic Gymnastics  |\n",
            "|Karate               |\n",
            "|Triathlon            |\n",
            "|Badminton            |\n",
            "|Canoe Sprint         |\n",
            "|Athletics            |\n",
            "|Cycling Track        |\n",
            "|Beach Volleyball     |\n",
            "+---------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Sample of unusual names (if any):\n",
            "+--------------------+--------------------+-------------+\n",
            "|                Name|                 NOC|   Discipline|\n",
            "+--------------------+--------------------+-------------+\n",
            "|     B. Sai Praneeth|               India|    Badminton|\n",
            "|CHADALAVADA ANAND...|               India|      Fencing|\n",
            "|DENAYER Felix Ver...|             Belgium|       Hockey|\n",
            "|              DENI .|           Indonesia|Weightlifting|\n",
            "|EBADIPOUR GHARA H...|Islamic Republic ...|   Volleyball|\n",
            "+--------------------+--------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Get unique NOC and Team combinations from each dataset\n",
        "print(\"=== NOC/Team Analysis ===\\n\")\n",
        "\n",
        "# Athletes Dataset Analysis\n",
        "athlete_teams = athletes_df.select(\"NOC\").distinct()\n",
        "print(f\"Number of unique NOC-Team combinations in Athletes: {athlete_teams.count()}\")\n",
        "\n",
        "# Medals Dataset Analysis\n",
        "medal_teams = medals_df.select(\"Team/NOC\").distinct()\n",
        "print(f\"Number of unique NOC-Team combinations in Medals: {medal_teams.count()}\")\n",
        "\n",
        "# Coaches Dataset Analysis\n",
        "coach_teams = coaches_df.select(\"NOC\").distinct()\n",
        "print(f\"Number of unique NOC-Team combinations in Coaches: {coach_teams.count()}\")\n",
        "\n",
        "# Show discrepancies in Athletes dataset\n",
        "print(\"\\n=== Athletes Dataset: Cases where NOC doesn't match expected Team pattern ===\")\n",
        "athletes_df.select(\"NOC\") \\\n",
        "    .distinct() \\\n",
        "    .orderBy(\"NOC\") \\\n",
        "    .show(truncate=False)\n",
        "\n",
        "# Compare NOCs across datasets\n",
        "athlete_nocs = set([row.NOC for row in athletes_df.select(\"NOC\").distinct().collect()])\n",
        "medal_nocs = set([row[\"Team/NOC\"] for row in medals_df.select(\"Team/NOC\").distinct().collect()])\n",
        "coach_nocs = set([row.NOC for row in coaches_df.select(\"NOC\").distinct().collect()])\n",
        "\n",
        "print(\"\\n=== NOC Comparison Across Datasets ===\")\n",
        "print(f\"Total unique NOCs in Athletes: {len(athlete_nocs)}\")\n",
        "print(f\"Total unique NOCs in Medals: {len(medal_nocs)}\")\n",
        "print(f\"Total unique NOCs in Coaches: {len(coach_nocs)}\")\n",
        "\n",
        "# Find NOCs that appear in one dataset but not others\n",
        "print(\"\\n=== NOC Discrepancies ===\")\n",
        "print(\"NOCs in Medals but not in Athletes:\", medal_nocs - athlete_nocs if medal_nocs - athlete_nocs else \"None\")\n",
        "print(\"NOCs in Athletes but not in Medals:\", athlete_nocs - medal_nocs if athlete_nocs - medal_nocs else \"None\")\n",
        "print(\"NOCs in Coaches but not in Athletes:\", coach_nocs - athlete_nocs if coach_nocs - athlete_nocs else \"None\")\n",
        "print(\"NOCs in Athletes but not in Coaches:\", athlete_nocs - coach_nocs if athlete_nocs - coach_nocs else \"None\")\n",
        "\n",
        "# Analyze Team naming patterns\n",
        "print(\"\\n=== Team Name Pattern Analysis ===\")\n",
        "print(\"Sample of Team names from Athletes dataset:\")\n",
        "athletes_df.select(\"NOC\") \\\n",
        "    .distinct() \\\n",
        "    .orderBy(rand()) \\\n",
        "    .show(10, truncate=False)\n",
        "\n",
        "print(\"\\nSample of Team names from Medals dataset:\")\n",
        "medals_df.select(\"Team/NOC\") \\\n",
        "    .distinct() \\\n",
        "    .orderBy(rand()) \\\n",
        "    .show(10, truncate=False)\n",
        "\n",
        "print(\"\\nSample of Team names from Coaches dataset:\")\n",
        "coaches_df.select(\"NOC\") \\\n",
        "    .distinct() \\\n",
        "    .orderBy(rand()) \\\n",
        "    .show(10, truncate=False)\n",
        "\n",
        "# Check for any unusual characters or patterns in NOC codes\n",
        "print(\"\\n=== Unusual NOC Patterns ===\")\n",
        "print(\"Athletes Dataset - NOCs not following standard 3-letter pattern:\")\n",
        "athletes_df.filter(~col(\"NOC\").rlike(\"^[A-Z]{3}$\")) \\\n",
        "    .select(\"NOC\") \\\n",
        "    .distinct() \\\n",
        "    .show()\n",
        "\n",
        "print(\"\\nMedals Dataset - NOCs not following standard 3-letter pattern:\")\n",
        "medals_df.filter(~col(\"Team/NOC\").rlike(\"^[A-Z]{3}$\")) \\\n",
        "    .select(\"Team/NOC\") \\\n",
        "    .distinct() \\\n",
        "    .show()\n",
        "\n",
        "print(\"\\nCoaches Dataset - NOCs not following standard 3-letter pattern:\")\n",
        "coaches_df.filter(~col(\"NOC\").rlike(\"^[A-Z]{3}$\")) \\\n",
        "    .select(\"NOC\") \\\n",
        "    .distinct() \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "U0Cvyga2Fghj",
        "outputId": "d6124472-8ad2-4673-ae16-99075705fff7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NOC/Team Analysis ===\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'select'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-0ad82847692b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Athletes Dataset Analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mathlete_teams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mathletes_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NOC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of unique NOC-Team combinations in Athletes: {athlete_teams.count()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'select'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (col, upper, trim, regexp_replace, when, count,\n",
        "                                 initcap, concat_ws, split, to_timestamp, coalesce)\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "def clean_olympics_data(spark, athletes_df, coaches_df, medals_df, teams_df):\n",
        "    \"\"\"\n",
        "    Main function to clean Tokyo Olympics dataset\n",
        "    Parameters:\n",
        "        spark: SparkSession object\n",
        "        athletes_df, coaches_df, medals_df, teams_df: Input dataframes\n",
        "    Returns:\n",
        "        Tuple of cleaned dataframes\n",
        "    \"\"\"\n",
        "\n",
        "    ###########################################\n",
        "    # 1. CLEAN ATHLETES DATA\n",
        "    ###########################################\n",
        "\n",
        "    cleaned_athletes = (athletes_df\n",
        "        # Standardize name format\n",
        "        .withColumn(\"Name\",\n",
        "            # Remove any leading/trailing spaces\n",
        "            trim(col(\"Name\"))\n",
        "            # Convert to Title Case (First letter capital)\n",
        "            .pipe(lambda c: initcap(c))\n",
        "            # Remove any non-ASCII characters while preserving diacritical marks\n",
        "            .pipe(lambda c: regexp_replace(c, \"[^\\p{L}\\p{M}\\s]\", \"\"))\n",
        "        )\n",
        "\n",
        "        # Clean Team column\n",
        "        .withColumn(\"Team\",\n",
        "            # Convert to uppercase for consistency\n",
        "            upper(trim(col(\"Team\")))\n",
        "            # Replace common variations\n",
        "            .pipe(lambda c: regexp_replace(c, \"USA\", \"UNITED STATES\"))\n",
        "            .pipe(lambda c: regexp_replace(c, \"UK\", \"UNITED KINGDOM\"))\n",
        "        )\n",
        "\n",
        "        # Clean Discipline column\n",
        "        .withColumn(\"Discipline\",\n",
        "            # Standardize discipline names\n",
        "            trim(initcap(col(\"Discipline\")))\n",
        "            # Remove any numerical suffixes\n",
        "            .pipe(lambda c: regexp_replace(c, \"\\d+\", \"\"))\n",
        "        )\n",
        "\n",
        "        # Remove duplicate entries\n",
        "        .dropDuplicates([\"Name\", \"Team\", \"Discipline\"])\n",
        "\n",
        "        # Handle missing values\n",
        "        .na.fill({\n",
        "            \"Discipline\": \"Unknown\",\n",
        "            \"Team\": \"UNAFFILIATED\"\n",
        "        })\n",
        "    )\n",
        "\n",
        "    ###########################################\n",
        "    # 2. CLEAN COACHES DATA\n",
        "    ###########################################\n",
        "\n",
        "    cleaned_coaches = (coaches_df\n",
        "        # Clean coach names similar to athletes\n",
        "        .withColumn(\"Name\",\n",
        "            trim(initcap(col(\"Name\")))\n",
        "            .pipe(lambda c: regexp_replace(c, \"[^\\p{L}\\p{M}\\s]\", \"\"))\n",
        "        )\n",
        "\n",
        "        # Standardize Event column\n",
        "        .withColumn(\"Event\",\n",
        "            # Remove special characters and standardize format\n",
        "            regexp_replace(trim(col(\"Event\")), \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
        "        )\n",
        "\n",
        "        # Clean Discipline column (same as athletes)\n",
        "        .withColumn(\"Discipline\",\n",
        "            trim(initcap(col(\"Discipline\")))\n",
        "            .pipe(lambda c: regexp_replace(c, \"\\d+\", \"\"))\n",
        "        )\n",
        "\n",
        "        # Remove duplicate coach entries\n",
        "        .dropDuplicates([\"Name\", \"Team\", \"Discipline\"])\n",
        "    )\n",
        "\n",
        "    ###########################################\n",
        "    # 3. CLEAN MEDALS DATA\n",
        "    ###########################################\n",
        "\n",
        "    cleaned_medals = (medals_df\n",
        "        # Standardize athlete names to match athletes table\n",
        "        .withColumn(\"Athlete\",\n",
        "            trim(initcap(col(\"Athlete\")))\n",
        "            .pipe(lambda c: regexp_replace(c, \"[^\\p{L}\\p{M}\\s]\", \"\"))\n",
        "        )\n",
        "\n",
        "        # Clean medal values\n",
        "        .withColumn(\"Medal\",\n",
        "            # Convert to uppercase and trim\n",
        "            upper(trim(col(\"Medal\")))\n",
        "            # Standardize medal names\n",
        "            .pipe(lambda c: when(c == \"GOLD MEDAL\", \"GOLD\")\n",
        "                           .when(c == \"SILVER MEDAL\", \"SILVER\")\n",
        "                           .when(c == \"BRONZE MEDAL\", \"BRONZE\")\n",
        "                           .otherwise(c))\n",
        "        )\n",
        "\n",
        "        # Handle team medals (where multiple athletes get same medal)\n",
        "        .dropDuplicates([\"Athlete\", \"Team\", \"Medal\", \"Event\"])\n",
        "    )\n",
        "\n",
        "    ###########################################\n",
        "    # 4. CLEAN TEAMS DATA\n",
        "    ###########################################\n",
        "\n",
        "    cleaned_teams = (teams_df\n",
        "        # Standardize team names\n",
        "        .withColumn(\"Team\",\n",
        "            upper(trim(col(\"Team\")))\n",
        "            .pipe(lambda c: regexp_replace(c, \"USA\", \"UNITED STATES\"))\n",
        "            .pipe(lambda c: regexp_replace(c, \"UK\", \"UNITED KINGDOM\"))\n",
        "        )\n",
        "\n",
        "        # Clean country names\n",
        "        .withColumn(\"Country\",\n",
        "            # Convert to title case for readability\n",
        "            initcap(trim(col(\"Country\")))\n",
        "            # Handle special cases\n",
        "            .pipe(lambda c: when(col(\"Team\") == \"ROC\", \"Russian Olympic Committee\")\n",
        "                           .otherwise(c))\n",
        "        )\n",
        "\n",
        "        # Remove duplicates\n",
        "        .dropDuplicates([\"Team\", \"Country\"])\n",
        "    )\n",
        "\n",
        "    ###########################################\n",
        "    # 5. DATA VALIDATION\n",
        "    ###########################################\n",
        "\n",
        "    def validate_cleaned_data(df, table_name):\n",
        "        \"\"\"\n",
        "        Validate the cleaned data and print statistics\n",
        "        \"\"\"\n",
        "        print(f\"\\nValidation for {table_name}:\")\n",
        "\n",
        "        # Check for nulls\n",
        "        null_counts = df.select([count(when(col(c).isNull(), c)).alias(c)\n",
        "                               for c in df.columns])\n",
        "        print(\"Null counts:\", null_counts.collect())\n",
        "\n",
        "        # Check for duplicates\n",
        "        duplicate_count = df.count() - df.dropDuplicates().count()\n",
        "        print(f\"Duplicate rows: {duplicate_count}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    # Validate all cleaned dataframes\n",
        "    cleaned_athletes = validate_cleaned_data(cleaned_athletes, \"Athletes\")\n",
        "    cleaned_coaches = validate_cleaned_data(cleaned_coaches, \"Coaches\")\n",
        "    cleaned_medals = validate_cleaned_data(cleaned_medals, \"Medals\")\n",
        "    cleaned_teams = validate_cleaned_data(cleaned_teams, \"Teams\")\n",
        "\n",
        "    ###########################################\n",
        "    # 6. CREATE QUALITY METRICS\n",
        "    ###########################################\n",
        "\n",
        "    def calculate_quality_metrics(df, table_name):\n",
        "        \"\"\"\n",
        "        Calculate and return data quality metrics\n",
        "        \"\"\"\n",
        "        total_rows = df.count()\n",
        "        null_rows = df.where(reduce(lambda x, y: x | y,\n",
        "                                  [col(c).isNull() for c in df.columns])).count()\n",
        "\n",
        "        metrics = {\n",
        "            \"table_name\": table_name,\n",
        "            \"total_rows\": total_rows,\n",
        "            \"null_percentage\": (null_rows / total_rows) * 100,\n",
        "            \"duplicate_percentage\": (duplicate_count / total_rows) * 100\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    # Store quality metrics for each table\n",
        "    quality_metrics = {\n",
        "        \"athletes\": calculate_quality_metrics(cleaned_athletes, \"Athletes\"),\n",
        "        \"coaches\": calculate_quality_metrics(cleaned_coaches, \"Coaches\"),\n",
        "        \"medals\": calculate_quality_metrics(cleaned_medals, \"Medals\"),\n",
        "        \"teams\": calculate_quality_metrics(cleaned_teams, \"Teams\")\n",
        "    }\n",
        "\n",
        "    return (cleaned_athletes, cleaned_coaches, cleaned_medals, cleaned_teams,\n",
        "            quality_metrics)\n",
        "\n",
        "###########################################\n",
        "# USAGE EXAMPLE\n",
        "###########################################\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Tokyo Olympics Data Cleaning\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Read your data\n",
        "# athletes_df = spark.read...\n",
        "# coaches_df = spark.read...\n",
        "# medals_df = spark.read...\n",
        "# teams_df = spark.read...\n",
        "\n",
        "# Clean the data\n",
        "cleaned_data = clean_olympics_data(spark, athletes_df, coaches_df,\n",
        "                                 medals_df, teams_df)\n",
        "\n",
        "# Access cleaned dataframes\n",
        "cleaned_athletes, cleaned_coaches, cleaned_medals, cleaned_teams, metrics = cleaned_data\n",
        "\n",
        "# Optional: Save cleaned data\n",
        "# cleaned_athletes.write.parquet(\"cleaned_athletes.parquet\")\n",
        "# cleaned_coaches.write.parquet(\"cleaned_coaches.parquet\")\n",
        "# cleaned_medals.write.parquet(\"cleaned_medals.parquet\")\n",
        "# cleaned_teams.write.parquet(\"cleaned_teams.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "4Me9t3VQLJSW",
        "outputId": "0e22a6ff-e18e-45d2-eb41-52160b084442"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'withColumn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-382e226e4d37>\u001b[0m in \u001b[0;36m<cell line: 211>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;31m# Clean the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m cleaned_data = clean_olympics_data(spark, athletes_df, coaches_df, \n\u001b[0m\u001b[1;32m    212\u001b[0m                                  medals_df, teams_df)\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-382e226e4d37>\u001b[0m in \u001b[0;36mclean_olympics_data\u001b[0;34m(spark, athletes_df, coaches_df, medals_df, teams_df)\u001b[0m\n\u001b[1;32m     20\u001b[0m     cleaned_athletes = (athletes_df\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Standardize name format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         .withColumn(\"Name\", \n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Remove any leading/trailing spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'withColumn'"
          ]
        }
      ]
    }
  ]
}